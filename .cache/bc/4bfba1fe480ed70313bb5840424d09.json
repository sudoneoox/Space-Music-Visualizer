{"id":"src/assets/libs/Audio.js","dependencies":[{"name":"C:\\Users\\Diego\\Downloads\\Documents\\three js\\AbsurbPlace\\package.json","includedInParent":true,"mtime":1624233666546},{"name":"web-audio-beat-detector","loc":{"line":1,"column":24},"parent":"C:\\Users\\Diego\\Downloads\\Documents\\three js\\AbsurbPlace\\src\\assets\\libs\\Audio.js","resolved":"C:\\Users\\Diego\\Downloads\\Documents\\three js\\AbsurbPlace\\node_modules\\web-audio-beat-detector\\build\\es2019\\module.js"}],"generated":{"js":"\"use strict\";\n\nvar _webAudioBeatDetector = require(\"web-audio-beat-detector\");"},"sourceMaps":{"js":{"mappings":[{"generated":{"line":3,"column":0},"source":"src/assets/libs/Audio.js","original":{"line":1,"column":0}}],"sources":{"src/assets/libs/Audio.js":"import { analyze } from 'web-audio-beat-detector';\r\n\r\n// when the scene is done initializing, the function passed as `callback` will be executed\r\n// then, every frame, the function passed as `update` will be executed\r\n// export default function Framework( callback, update )\r\n// {\r\n//     //var gui = new DAT.GUI();\r\n\r\n//     var framework = {\r\n//         //gui: gui,\r\n//         paused: false,\r\n//         audioStartOffset: 0,\r\n//         audioStartTime: 0,\r\n//         audioBuffer: undefined,\r\n//         cameraPaused: false,\r\n//         automaticSwitchingOn: true,\r\n//         audioSourceBuffer: null\r\n//     };\r\n\r\n//     function createAndConnectAudioBuffer( )\r\n//     {\r\n//         // create the source buffer\r\n//         framework.audioSourceBuffer = framework.audioContext.createBufferSource( );\r\n//         // connect source and analyser\r\n//         framework.audioSourceBuffer.connect( framework.audioAnalyser );\r\n//         framework.audioAnalyser.connect( framework.audioContext.destination );\r\n//     }\r\n\r\n//     this.playAudio = function( file )\r\n//     {\r\n//         createAndConnectAudioBuffer( );\r\n//         framework.audioFile = file;\r\n\r\n//         var fileName = framework.audioFile.name;\r\n//         document.getElementById( 'guide' ).innerHTML = \"Playing \" + fileName;\r\n//         var fileReader = new FileReader( );\r\n\r\n//         fileReader.onload = function( e )\r\n//         {\r\n//             var fileResult = fileReader.result;\r\n//             framework.audioContext.decodeAudioData( fileResult, function( buffer )\r\n//             {\r\n//                 framework.audioSourceBuffer.buffer = buffer;\r\n//                 framework.audioBuffer = buffer;\r\n//                 framework.audioSourceBuffer.start( );\r\n//                 framework.audioSourceBuffer.loop = true;\r\n//                 analyze( framework.audioSourceBuffer.buffer ).then( ( bpm ) =>\r\n//                     {\r\n//                         // the bpm could be analyzed \r\n//                         framework.songBPM = bpm;\r\n//                     } )\r\n//                     .catch( ( err ) =>\r\n//                     {\r\n//                         // something went wrong \r\n//                         console.log( \"couldn't detect BPM\" );\r\n//                     } );\r\n//             }, function( e ) { \"Error with decoding audio data\" + e.err } );\r\n//         };\r\n//         fileReader.readAsArrayBuffer( framework.audioFile );\r\n//     }\r\n\r\n//     // run this function after the window loads\r\n//     window.addEventListener( 'load', function( )\r\n//     {\r\n//         // set up audio processing\r\n//         framework.audioContext = new( window.AudioContext || window.webkitAudioContext )( );\r\n//         // create analyser\r\n//         framework.audioAnalyser = framework.audioContext.createAnalyser( );\r\n//         framework.audioAnalyser.smoothingTimeConstant = 0.3;\r\n//         framework.audioAnalyser.fftSize = 1024;\r\n//         // create the source buffer\r\n//         framework.audioSourceBuffer = framework.audioContext.createBufferSource( );\r\n\r\n//         // connect source and analyser\r\n//         framework.audioSourceBuffer.connect( framework.audioAnalyser );\r\n//         framework.audioAnalyser.connect( framework.audioContext.destination );\r\n\r\n//         // add drag and drop functionality for uploading audio file\r\n//         window.addEventListener( \"dragenter\", dragenter, false );\r\n//         window.addEventListener( \"dragover\", dragover, false );\r\n//         window.addEventListener( \"drop\", drop, false );\r\n//         // add pausing functionality via spacebar\r\n//         window.addEventListener( \"keypress\", keypress, false );\r\n\r\n//         function dragenter( e )\r\n//         {\r\n//             e.stopPropagation( );\r\n//             e.preventDefault( );\r\n//         }\r\n\r\n//         function dragover( e )\r\n//         {\r\n//             e.stopPropagation( );\r\n//             e.preventDefault( );\r\n//         }\r\n\r\n//         function drop( e )\r\n//         {\r\n//             e.stopPropagation( );\r\n//             e.preventDefault( );\r\n//             if ( framework.audioFile == undefined )\r\n//             {\r\n//                 playAudio( e.dataTransfer.files[ 0 ] );\r\n//             }\r\n//             else\r\n//             {\r\n//                 // stop current visualization and load new song\r\n//                 framework.audioSourceBuffer.stop( );\r\n//                 playAudio( e.dataTransfer.files[ 0 ] );\r\n//             }\r\n//         }\r\n\r\n\r\n//         // assign THREE.js objects to the object we will return\r\n\r\n//         this.updateframework = function( )\r\n//         {\r\n//             update( framework )\r\n//         }\r\n\r\n//         // we will pass the scene, gui, renderer, camera, etc... to the callback function\r\n//         return callback( framework );\r\n//     } );\r\n\r\n// }"},"lineCount":null}},"error":null,"hash":"6a1e4c61ede4a3fc7144574e89180141","cacheData":{"env":{}}}